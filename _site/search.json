[
  {
    "objectID": "testbenches.html",
    "href": "testbenches.html",
    "title": "Software Test Benches",
    "section": "",
    "text": "top Testbench (HSOSC)\n\n\n\n\n\n\nFigure 1: Testbench for the top module showing that HSOSC toggles.\n\n\n\nFrom the testbench results of the top module (Figure 1), we can see that HSOSC successfully triggered, which means the int_osc clock is successfully sent to the rest of the modules which all share int_osc as a clock.\n\n\nsynchronizer Testbench\n\n\n\n\n\n\nFigure 2: Testbench for the synchronizer module showing that the sync_out output gets the async_in after two clock cycles.\n\n\n\nFrom the testbench results of the synchronizer module (Figure 2), we can see that the sync_out output matches the async_in input after two clock cycles. The input and output signals are all 1-bit due to the inputs into the top module all being 1-bit signals of HIGH or LOW.\n\n\nclk_div Testbench\n\n\n\n\n\n\nFigure 3: Testbench for the clk_div module showing that the clk_enable output toggles when the counter reaches 2000000 or 2000000 cycles.\n\n\n\nFrom the testbench results of the clk_div module (Figure 3), we can see that the clk_enable output successfully toggles at 2000000 clock cycles. This slows down the clock for the other modules such that the change in head positions and the led pattern are visible to the eye.\n\n\nangle_decoder Testbench\n\n\n\n\n\n\nFigure 4: Testbench for the angle_decoder module showing that the each state is visited correctly. The state changes from CLOSED to OPENED after captouch goes high, from OPENED to SLIGHT when irblock goes high, stays at SLIGHT when irblock stays high, back to OPENED from SLIGHT when irblock goes low, and akways back to CLOSED when estop goes high.\n\n\n\nFrom the testbench results of the angle_decoder module (Figure 4), we can see that the program successfully moves to the right state when prompted by the expected input. CLOSED goes to OPENED when captouch goes high an the nose is touched. Then, the program moves from OPENED to SLIGHT when irblock goes high, and stays at SLIGHT when irblockis still high. And then only moves back to OPENED from SLIGHT when irblock goes low. The state goes to CLOSED when estop is is prompted.\n\n\npwmgen Testbench\n\n\n\n\n\n\nFigure 5: Testbench for the pwmgen module shows that the pwm output successfully toggles LOW when counter is 30000 and angle is 8'd30.\n\n\n\nFrom the testbench results of the pwmgen module above, we can see that the pwm output successfuly toggles from high to low when counter is 30000 when the input angle is 8'd30 (Figure 5). This means the servo is successfully sent the PWM signal for the CLOSED state.\n\n\n\n\n\n\nFigure 6: Testbench for the pwmgen module shows that the pwm output successfully toggles LOW when counter is 40000 and angle is 8'd90.\n\n\n\nFrom the testbench results of the pwmgen module above, we can see that the pwm output successfuly toggles from high to low when counter is 40000 when the input angle is 8'd90 (Figure 6). This means the servo is successfully sent the PWM signal for the SLIGHT state.\n\n\n\n\n\n\nFigure 7: Testbench for the pwmgen module shows that the pwm output successfully toggles LOW when counter is 60000 and angle is 8'd150.\n\n\n\nFrom the testbench results of the pwmgen module above, we can see that the pwm output successfuly toggles from high to low when counter is 60000 when the input angle is 8'd150 (Figure 7). This means the servo is successfully sent the PWM signal for the OPEN state.\n\n\nled_pattern Testbench\n\n\n\n\n\n\nFigure 8: Testbench for the led_pattern module shows that the leds and ledstrip output match expected outputs with the expected input triggers. The pattern_index also successfully increases in the expected order.\n\n\n\nFrom the testbench results of the led_pattern module (Figure 8), we can see that the pattern_index reaches the right numbers in the right order and begins increasing in response to the appropriate input. Whe play goes high, the pattern_index increases from 0 to 11 and stays at 11 until roar goes high. Then, the index increases up to 17 before stopping the pattern and returning to pattern 11. This matches the software and expected outputs, meaning the LED show will match the expected pattern based on the expected inputs."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Reference Links",
    "section": "",
    "text": "Servo Motor PWM tutorial\nIR Proximity Sensor inspo\nDFPlayer Mini tutorial\n\n\n\n\n\nDFPlayer Datasheet\nSTM32L432KC Datasheet\niCE40 UltraPlus Family Data Sheet\n\n\n\n\n\nToothless Popcorn Bucket STL"
  },
  {
    "objectID": "references.html#helpful-tutorialsinspo",
    "href": "references.html#helpful-tutorialsinspo",
    "title": "Reference Links",
    "section": "",
    "text": "Servo Motor PWM tutorial\nIR Proximity Sensor inspo\nDFPlayer Mini tutorial"
  },
  {
    "objectID": "references.html#datasheets",
    "href": "references.html#datasheets",
    "title": "Reference Links",
    "section": "",
    "text": "DFPlayer Datasheet\nSTM32L432KC Datasheet\niCE40 UltraPlus Family Data Sheet"
  },
  {
    "objectID": "references.html#stl-files",
    "href": "references.html#stl-files",
    "title": "Reference Links",
    "section": "",
    "text": "Toothless Popcorn Bucket STL"
  },
  {
    "objectID": "mechanical.html",
    "href": "mechanical.html",
    "title": "Mechanical CAD and Designs",
    "section": "",
    "text": "All CAD files were printed on a Bambu Lab Design 3D printer. This greatly reduced the cost of the mechanical portion. The project will be significantly more expensive without access to a 3D printer and different colored filament. The 3D print can be painted but due to its smooth surface, the print will require sanding to hold paint."
  },
  {
    "objectID": "mechanical.html#dragon-head",
    "href": "mechanical.html#dragon-head",
    "title": "Mechanical CAD and Designs",
    "section": "Dragon Head",
    "text": "Dragon Head\nIn order to detect the Capacitive Touch Sensor through the PLA, the inside of the nose was cut out using needle nose pliers, a soldering iron (not reccommended), sand paper, and pure will (Figure 2). The Capacitive Touch Sensor was then secured to the inside using hot glue and super glue and frequently tested to be sure it could be detected.\n\n\n\n\n\n\nFigure 2: Physical model showing the inside cut out where the Capacitive Touch Sensor lay\n\n\n\nSince it was only printed with black PLA, the eyes were painted on with a green acrylic paint pen."
  },
  {
    "objectID": "mechanical.html#dragon-body-1",
    "href": "mechanical.html#dragon-body-1",
    "title": "Mechanical CAD and Designs",
    "section": "Dragon Body",
    "text": "Dragon Body\nIn order to let the wires pass into the dragon stand box underneath, the body was mechanically modified by drilling into the bottom with a hole saw set (Figure 3).\n\n\n\n\n\n\nFigure 3: Set Up with the hole made by the Hole Saw"
  },
  {
    "objectID": "mechanical.html#bottom-jaw-ir-sensor-holder",
    "href": "mechanical.html#bottom-jaw-ir-sensor-holder",
    "title": "Mechanical CAD and Designs",
    "section": "Bottom Jaw (IR Sensor Holder)",
    "text": "Bottom Jaw (IR Sensor Holder)\n\n\n\n\n\n\nFigure 4: CAD for the bottom jaw. The extrusion below the rectangular opening screws into the lever arm that is manipulated by the servo motor. The raised extrusion with two holes houses the IR LED and the IR-PD for the hand detection sensor. The slant on the outside rim slides into the dragon body"
  },
  {
    "objectID": "mechanical.html#top-jaw-servo-holder",
    "href": "mechanical.html#top-jaw-servo-holder",
    "title": "Mechanical CAD and Designs",
    "section": "Top Jaw (Servo Holder)",
    "text": "Top Jaw (Servo Holder)\n\n\n\n\n\n\nFigure 5: CAD for the top jaw. The rectangular extrusion holds the servo motor with M2 screws. The rectangular extrusion is curved on the end to fit the curved inside of the head."
  },
  {
    "objectID": "mechanical.html#lever-arm",
    "href": "mechanical.html#lever-arm",
    "title": "Mechanical CAD and Designs",
    "section": "Lever Arm",
    "text": "Lever Arm\n\n\n\n\n\n\nFigure 6: CAD for the lever arm that screws into the servo motor and into the bottom jaw. Due to the bottom jaw being screwed on to the heavier dragon body, when the servo pushes the lever arm down, the top jaw opens up."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Toothless Candy Bucket Project",
    "section": "",
    "text": "The Inventors &lt;3\n\n\n\nProject Introduction\nCaiya and Erin designed an interactive candy bucket inspired by the lovable dragon, Toothless, from the film How to Train Your Dragon. Taken from the iconic scene where Toothless places his snout on Hiccup’s outstretched palm, the candy bucket opens its mouth when the nose is touched and plays a clip from the awe-inspiring theme song, “Test Drive”.\n\n\n\nProject Abstract\nThe project takes inspiration from Halloween candy buckets to create a Toothless suprise complete with music, lights, and an interactive jaw mechanism. The final working prototype starts with the participant rubbing Toothless’ nose to trigger the capacitive touch sensor which will trigger the servo motor to open the mouth while the theme music plays via the DFP in the background. Then as the participant goes into the mouth to grab a piece of candy, the IR proximity sensor is triggered and the servo motor is set to close on the participants hand while a ROAR plays on the DFP in the background before going back to it’s initial position. The project also includes an E-stop button to reset the process. The touch sensor and DFP player are interfaced via the MCU as well as the IR proximity sensor through a Analog-to-Digital Converter (ADC). The servo motor and LEDs are interfaced via the FPGA where the LEDs recieve a SRAM signal from where the embedded LED show memories are stored.\n\n\nProject Demonstration\nHere are two videos of the working product! The first video below is during our project showcase day with our clean product and dragon stand implemented.\n\n\nVideo\nVideo from project demonstration of the final product. Toothless opens its mouth when the nose is touched and “bites” the user when a hand is placed over the middle of the mouth with candy inside.\n\n\nDue to the background audio obscuring the music from the speaker, the second video below is provided of the working product before cleaning to showcase the music.\n\n\nVideo\nVideo from earlier stage. The music being played is more audible in this video. The theme song “Test Drive” plays when the nose is touched and Toothless’ roar is played when a hand is detected.\n\n\n\n\nOpen Source Code\nThe link to all code used for this project can be found on Github here."
  },
  {
    "objectID": "electrical.html#capacitive-touch-sensor-circuit",
    "href": "electrical.html#capacitive-touch-sensor-circuit",
    "title": "Electrical Schematics and Design",
    "section": "1. Capacitive Touch Sensor Circuit",
    "text": "1. Capacitive Touch Sensor Circuit\nThe MCU uses a Capacitive Touch Sensor to detect a user’s hand to trigger the start of the whole sequence (Figure 1). The GPIO receives that signal on PA8 which simultaneously triggeres PA5 which is electrically connected to P47 to send a signal to the FPGA components as well.\nThe Capactive Touch Sensor receives 5V and ground from the circuit. It works by applying a small voltage to create a constant electrostatic field on one surface. When that conductive material is touched by a human, a capacitor is formed from the virtual ground that the user provides. This is seen in practically every smart device around us today.\nWe tested it by connecting to a multimeter to see the max voltage that could be received on the GPIO pin when detecting a finger touch.\n\n\n\n\n\n\nFigure 1: Electrical schematic for the Capacitive Touch sensor. The exact module is a TTP223 Touch Sensor Module and can be found on DigiKey and Amazon. The pins for the input signal into the STM are labeled. The 5V and GND are sourced from the STM. The 5V and GND connection and all other connections into the STM are not pictured in this image.\n\n\n\nOne of the main difficulties with this sensor was integrating it mechanically as it had to be detectable through the 3D printed PLA that we used for Toothless. So there were many moments where we thought there was something going wrong on the electrical and software side when it was was the mechanical.\nOne thing that we did right before demo day was that the Capacitive Touch Sensor would randomly trigger when the dragon box was even touched. This is wherewe found that the make to femal connector that we placed into the GPIO pin would easily wiggle around causing the signal to flicker. So we replace it…stranded wire for the win."
  },
  {
    "objectID": "electrical.html#ir-proximity-sensor-circuit",
    "href": "electrical.html#ir-proximity-sensor-circuit",
    "title": "Electrical Schematics and Design",
    "section": "2. IR Proximity Sensor Circuit",
    "text": "2. IR Proximity Sensor Circuit\nThe MCU also deals with detecting hand placement into the mouth using an IR Proximity sensor. The sensor works by placing an IR LED and IR detector pair next to each other such that the IR detector takes the IR light that reflects off an object that comes near the top of the IR light (Figure 2). The closer the object, the stronger the IR intensity of the reflection.\n\n\n\n\n\n\nFigure 2: Sketch demonstrating the IR LED reflecting off an object hovering over the LED into the IR detector. The closer the hand, the strong the IR intensity of the reflection and the more current is produced by the IR-PD.\n\n\n\nThe circuit is heavily inspired by AutoDesk Instructuable’s Proximity Sensor, but without a potentiometer for changing the distance of the object away from the sensor that the circuit can detect. The circuit schematic is shown below (Figure 3). Note that the IR LED is in the opposite direction as the IR Photodetector (IR-PD).\n\n\n\n\n\n\nFigure 3: Electrical schematic for the IR proximity sensor.The InfraRed light reflected into the IR photo-detector produces a current that increases the voltage over the resistor in series with the IR-PD that is then compared by the LM385 op-amp. The op-amp configuration provides a non-inverting gain of approximately 45. The pins for the LM385 op-amp and the input signal into the STM are labeled. The 5V and GND are sourced from the STM. The 5V and GND connection and all other connections into the STM are not pictured in this image.\n\n\n\nThe more InfraRed light that falls on the IR-PD, the more current that flows through the PD. This current then flows through the 10kΩ resistor connecting the cathode of the PD to ground which increases the voltage potential across the resistor that is seen by the positive terminal of the LM358 op-amp (Pin 2). The op-amp is configured with a non-inverting gain based on the resistorconnected between vout and the negative terminal (R1) and the resistor connected between the negative terminal of the op-amp to ground (R2). The gain of the non-inverting op-amp (A) follows the equation below.\n\\[\nA_{non-inverting} = 1 + \\frac{R_{1}}{R_{2}} = 1 + \\frac{21kΩ}{470Ω} = 44.7\n\\]\nIn Figure 3, because we used R1 = 21kΩ and R2=470Ω, the gain of our circuit was around 45. This allowed for a hand near the sensor to be detected but the roof of the mouth to not be detected when the jaw was open. For debugging the circuit, we recommend to place an LED in series with a resistor to ground at the voltage output of the op-amp. The LED brightness should increase as the object gets closer to the LED pair."
  },
  {
    "objectID": "electrical.html#dfplayer-mini-circuit",
    "href": "electrical.html#dfplayer-mini-circuit",
    "title": "Electrical Schematics and Design",
    "section": "3. DFPlayer Mini Circuit",
    "text": "3. DFPlayer Mini Circuit\nOne of the big issues for the DFPlayer was that the RX and TX channels were swapped for the longest time. Although a seemingly simple mistake, it was one that tripped us up for a while because there wasn’t a proper datasheet to reference of each of the DFPlayers pin outs. Additionally the DFPlayer works on its own independently so if all your files are named and numbered correctly (which was also a big issue at first) you can use the ADKEY and IO ports to trigger play different segments on the TF card. It was unclear for a while whether it was recieving an electrical signal or what we were producing via the software’s UART signals.\nThe circuit itself is largely inspired by sample circuits on the Picaxe Datasheet that we later found as well as a MP3-TF-16p Tutorial on Youtube. The schematic for the DFPlayer mini is shown below (Figure 4)\nSince the DFPlayer was completely controlled via the MCU no signal was sent to the FPGA.\n\n\n\n\n\n\nFigure 4: Electrical schematic for the DFP Mini Player. The DFPlayer had pins that directly correleated to RX and TX for UART serial input/output. The capacitor was to reduce noise like what we had similarly seen on Lab 4. The pins for the input signal into the STM are labeled. The 5V and GND are sourced from the STM. All other connections into the STM are not pictured in this image.\n\n\n\nOne big thing we learned was to use stranded wire for as many things as we can because the speaker and various connections often broke off without notice during the debugging process."
  },
  {
    "objectID": "electrical.html#servo-motor-circuit",
    "href": "electrical.html#servo-motor-circuit",
    "title": "Electrical Schematics and Design",
    "section": "1. Servo Motor Circuit",
    "text": "1. Servo Motor Circuit\nOne issue we ran into was the power the servo motor drained when moving which caused the music on the DFPlayer mini to cut out when the servo was in action and meant that we couldn’t play music at the same time that the jaw opened. To circumvent this, we powered the servo motor with a 5V power supply separate from the 5V provided by the MCU. It is important to connect the ground of the servo and the ground of the power supply to the same ground as the MCU and FPGA such that they all share common ground. The issue of common ground ended up being a nasty and almost invisible problem that was hard to debug later when the circuit board and breadboard were hidden underneath our box stand.\nAnother way we ensured the servo inject noise into the MCU was using a non-inverting NPN open-collector buffer. This also allowed us to provde the servo with the necessary clean high and low signal for the PWM. The FPGA pins only supply 3.3V which has potential to muddle the PWM signal where the FPGA would see 3.3V as low rather than as high, thus using the two NPN transistor configuration created a non-inverting buffer that pulled the 3.3V signal to a 5V signal. The schematic for the non-inverting, two NPN buffer and servo motor is below (Figure 5).\n\n\n\n\n\n\nFigure 5: Electrical schematic for the servo motor. The servo is powered with a separate 5V power supply. The pwm signal from the FPGA goes through an NPN transistor circuit tied to 3.3V that inverts the PWM signal. Then the inverted signal goes through another NPN circuit tied to 5V that inverts the signal back to the original PWM signal and pulls the 3.3V up to 5V for the servo to cleanly read high. The 1kΩ resistor between the FPGA and the base of the transistor limits base current and protects the FPGA pin while the 4.7kΩ resistor acts as a pull-up resistor for the collector. All other connections into the FPGA including 3.3V and GND are not pictured.\n\n\n\nThe 1kΩ resistor from the FPGA pin (P12) to the base of the NPN transistor protects the FPGA pin by limiting base current while the 4.7kΩ resistor acts as a pull-up resistor for the collector. We used 2N9304 transistors which has the emitter on Pin 1, the base on Pin 2, and the collector on Pin 3 (Figure 5). If using a different NPN transistor, be sure to check the transistor’s pinout."
  },
  {
    "objectID": "electrical.html#led-array-circuit",
    "href": "electrical.html#led-array-circuit",
    "title": "Electrical Schematics and Design",
    "section": "2. LED Array Circuit",
    "text": "2. LED Array Circuit\nThe LED array circuit (Figure 6) is simply 10 LEDs wired with a 1kΩ resistor in series to ground. The LED strip uses another 2N3904 NPN transistor that uses a signal from the FPGA to decided whether or not to turn the light strip on. We had to use a separate power supply that provided 12V as the 5V from the MCU and the 3.3V from the FPGA were too low to power the LED strip.\n\n\n\n\n\n\nFigure 6: Electrical circuit for the LED array circuit. Each individual LED is connected to a 1kΩ resistor tied to ground. The first 5 LEDs are green while the other 5 are white. The LED strip is powered by a separate 12V power supply and the anode is connected to the collector of a 2N3904 transistor. The 10kΩ resistor between the FPGA and the base of the transistor limits base current and protects the FPGA pin. The emitter of the transistor is tied to ground. All other connections into the FPGA including GND are not pictured.\n\n\n\nIt is important to note that unlike the servo motor, the LED light strip is placed in series with the voltage source such that the cathode of the light strip is attached to the positive terminal of the power supply and the anode is connected to the collector (Pin 3) of the transistor. The resistor between the FPGA pin (P13) is greater than that for the servo as the voltage being supplied from the power supply is also much greater. When programming the LEDs, the order can be chosen based on which pins you send a high signal to first. For our purposes, we lighted in a certain order but placed the LEDs not in order to create a slightly random light show. See the software design section for more details."
  },
  {
    "objectID": "future.html",
    "href": "future.html",
    "title": "Future Iterations and Work",
    "section": "",
    "text": "Mechanical Hinge\nOne of the most pressing issues that happened during Demo Day was that a user accidentally pressed down the head too hard while activating the capacitive sensor, causing the servo to push hard against the stiff restraint and attached head resulting in the servo holder to snap off and the hinge holding the dragon head and body to break.\nIf we were to reprint, we would use a higher infill density to strengthen the part, but also screw the connection of the head and the body then placing two screw on either side of the holding screw to be able to move the hinges of the head. We think this would be much more secure in keeping the connection together. We would also make sure to either glue the servo down to the top jaw or screw the attachment such that it can’t snap.\n\n\nDebugging Ease\nWe also found that the head was hard to debug as we had hot glued the roof of the mouth to the head piece. We would definitely use screws instead to connect the jaw pieces to their respective dragon body parts that way assembly and disassembly are easier.\nThe wiring was also somewhat of a nightmare to work with. It is likely we would want to start out with much larger wires when putting things together that way we could wire the dragon into the breadboard with the box fully lifted.\n\n\nBigger Model\nDue to limitations on printing size and printing issues with the Makerspace 3D printers, we weren’t able to print Toothless any bigger, but we would love to have a bigger model to hold more candy and also have more space for the servo motor in the head."
  },
  {
    "objectID": "materials.html",
    "href": "materials.html",
    "title": "Toothless Candy Bucket",
    "section": "",
    "text": "The Bill of Materials. (BOM) for making the full project can be found below:"
  },
  {
    "objectID": "materials.html#bom",
    "href": "materials.html#bom",
    "title": "Toothless Candy Bucket",
    "section": "BOM",
    "text": "BOM\n\n\n\nItem\nPart/ASIN Number\nAmount\nUnit Price\nTotal\n\n\n\n\nHiLetgo 2pcs mp3 Player Mini MP3 Player Audio Voice Module TF Card U Disk Board for DFPlayer Audio Voice Music Module\nB01D1D0E7Q\n1\n$8.99\n$8.99\n\n\n2 Pack TF Card 8GB with Adapter, High Speed Memory Card, UHS-I C10 A1 Memory TF Card for Tablet/Mobile Phone/Camera/Car Audio/Game Console (TF162 Red Gold 8GB)\nB0CYT2KL98\n1\n$7.99\n$7.99\n\n\nSOCAL-LED LIGHTING 30cm 12” Purple Flexible LED Strips High Power Bright 5050 12 SMD Car DRL Under Dash Accent Light, Waterproof, Cuttable, Pack of 2\nB00RT2WCNK\n1\n$6.99\n$6.99\n\n\nMiuzei MG996R Servo Motor Metal Gear High Speed Torque Digital Servo for RC DIY Helicopter Car Boat Robot (2)\nB0BZ4QMSM2\n1\n$14.99\n$14.99\n\n\nWWZMDiB 6Pcs TTP223B Digital Capacitive Touch Sensor Switch Module DC 2~5.5V for Arduino Raspberry Pi DIY\nB0BG2694RX\n1\n$6.99\n$6.99\n\n\n80 Ohm 4 Watt Speaker\nSourced from Stockroom\n1\nN/A\nN/A\n\n\nCapacitors/Resistors/Jumper Cables\nSourced from Stockroom\nTBD\nN/A\nN/A\n\n\nTotal Cost: $45.95"
  },
  {
    "objectID": "members.html",
    "href": "members.html",
    "title": "The Team",
    "section": "",
    "text": "The Team\n\n\nCaiya Coggshall HMC ’26\n\nCaiya Coggshall is a senior engineering major at Harvey Mudd College with a concentration in Mechanical, Manufacturing, and Computer systems.\n​Some of her past experience involves fabricating and testing fixtures to support the development of a Class III medical device as a manufacturing engineering intern at E2. She’s prototyped a fully mechanical autoinjector for hormonal acne treatment through Indomo. In research, she managed a cell culture facility and contributed to experimental systems for cancer and nanoparticle drug delivery. On campus, she serves as a machine shop proctor, training students in milling, lathe operation, and various other tooling machines. Lastly, she leads as the external operations coordinator of the tours program at Harvey Mudd College. The link to her personal portfolio can be found here\nShe’s drawn to projects that build real, physical systems and approach every problem with curiosity, attention to detail, and a drive to make things that actually work. After college, she hopes to find a job combining her mechanical and hardware interests to create biomedical devices.\n\n\nErin Wang HMC ’26\n\nErin Wang is a senior engineering major at Harvey Mudd College. Her love for theme parks like Disney and Universal Studios greatly sparked her interest in robotics and mechatronics specifically for building animatronics. One of her personal projects is to build the robot from the REPO game with 3D printed material and off-the-shelf servo motors. She was extremely excited to be able to bring her passion for animatronics alive through this project. The link to her Github can be found here.\nAfter college, she aims to apply for Masters programs robotics, electrical engineering, or mechanical engineering. When she is not working hard in her classes, music and food fill her life. She loves to dance and sing as well as compose music, and she is always willing to try a new food place."
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software Programs and Design",
    "section": "",
    "text": "All code can be found in the Github for this project."
  },
  {
    "objectID": "software.html#capacitive-touch-sensor-code",
    "href": "software.html#capacitive-touch-sensor-code",
    "title": "Software Programs and Design",
    "section": "1. Capacitive Touch Sensor Code",
    "text": "1. Capacitive Touch Sensor Code\nThe code uses GPIO signals to determine when the capvalue is high by digitally reading the input pin that the capacitive touch sensor is connected to. When that value goes high, we digitally write to an output GPIO pin (PA5) that is connected electrically to an input FPGA pin (P47). Thus, the incoming capacitive signal when a user touches the nose tells the servo motor and LEDs to trigger and additionally plays the theme song on the DFP player.\nIn order to not check the capacitive signal when the jaw is open and the robot is only waiting for the IR detector to go off, we implemented a Finite State Machine (FSM) such that we wait for the capacitive signal to go high in the state STATE_WAIT_FOR_CAP, and then when the nose is touched and the capacitive signal toggles we move to state STATE_IR_MODE\" where we no longer look for signals from the capacitive touch sensor until Toothless is reset for a new user."
  },
  {
    "objectID": "software.html#ir-proximity-sensor-code",
    "href": "software.html#ir-proximity-sensor-code",
    "title": "Software Programs and Design",
    "section": "2. IR Proximity Sensor Code",
    "text": "2. IR Proximity Sensor Code\nThe IR Proximity Sensor produces a voltage when a hand comes near the IR LED which sends a signal to a GPIO pin (PA0) that is specifically programmed with the alternate function that interfaces with the Analog-to-Digital Converter on the MCU.\nOnce the Capacitive Touch Sensor is triggered the program moves to the next FSM state called STATE_IR_MODE where we are checking if the irvalue input (from the handdetection() function) is high, in which case a signal is sent to an FPGA pin (Pin 2) to trigger the servo motor and LEDs and the ROAR sound is played on the DFP player.\n\n2.1 ADC Initialization and Functions\nWe separated the code for ADC specific functions and initialization into its own header and .C file for organization. The ADC was intialized in file STM32L432KC_ADC.c where the ADC clock is enabled and set as the system clock (8MHz) divided by 4 (2MHz) to run at a safe but quick speed for reading the analog signals. Because we used the CKMODE register to set the division, we did not need to use the prescaler for the ADC to divide the clock further. We then turned off Deep Power-Down Mode, enabled the voltage regulator, and then delayed for 20μs as per the datasheet. After delaying, the ADC could then be calibrated and configured. We used a single, right-aligned, 12-bit configuration then configured using 1 conversion at a time.\nThe function readADC() then starts the conversion, waits for the conversion to be finished, then reads off the value through the ADC where it’s called later on in the handdetection() function.\n\n\n2.2 Hand Detection program\nThe handdetection() function calls on the readADC() function to read in the converted analog signal from the IR Proximity sensor as a digital value. This digital value is compared against a value we set called HIGH_THRESHOLD which we define in main.h. If the value we receive is above that threshold we determine a hand is being detected and return a digital high, otherwise it stays low. The HIGH_THRESHOLD value was determined through trial and error using the debugger tool and using a printf statement to visually see the incoming digital values when the the open jaw was over the sensor versus when a hand was close to the sensor. The value was chosen such that the sensor was not activated from the bottom of Toothless’ head when the jaw was open slightly or open all the way otherwise the IR would constantly be detecting in an endless loop. A delay of 2 seconds was added between sending the irvalue from pin PB3 to the FPGA on pin P2 and then writing PB3 back to 0 so that the MCU wasn’t checking incoming values from the IR sensor when the jaw was closing on the hand. This gave a good enough pause for the roar to play and the mouth to close and open before another object could be detected."
  },
  {
    "objectID": "software.html#dfplayer-mini-code",
    "href": "software.html#dfplayer-mini-code",
    "title": "Software Programs and Design",
    "section": "3. DFPlayer Mini Code",
    "text": "3. DFPlayer Mini Code\nThe DFPlayer was encoded entirely on the MCU interfacting with the Capacitive Touch Sensor and IR Proximity Sensor to know when to play the Theme song and ROAR, respectively.\nThe DFPlayer used UART (Universal Asynchronous Receiver/Transmitter) for serial communication in order to play mp3 files from the TF card connected on it’s hardware. The code used a standard baud rate of 9600 as specified on the datasheet for the USART1 register and a rate of 115200 for debugging on the USART2 register.\nTwo USART addresses are established in tow pointer variables dfp_usart and dbg_usart. Based on the datasheet the DFPlayer recieves a 10-byte frame which is split up in the function DFP_SendCommand() where we’re able to change the bits for the command, feedback, parameter high byte, parameter low byte, checksum high, and checksum low.\nSince we didn’t want any feedback we set that byte to 00 for no reply. The parameters where split to keep the full 16 bits between the high and low bytes.\nOther functions such as DFP_Play(), DFP_Pause(), and more would call on DFP_SendCommand() to complete different functions. On the datasheet it identified different addresses associated with different commands such as 0x06 to specify volume, OxOE to pause the song, OxOF to play a specific file on the TF and many more.\nFor more details on specific commands, this is the datasheet we referenced:\nDFPlayer Mini Datasheet with UART Instructions\nThen in the while loop, if the Capacitive Touch Sensor is high then after the FPGA signal is sent, the DFP_PlayFolderTrack() function is called to play the theme song Test Drive that’s labeled 001.mp3 in the 01 folder in the TF card.\nSimilarly when the IR Proximity Sensor is high then after the FPGA signal is sent then the Roar sound on the 002.mp3 file is played."
  },
  {
    "objectID": "software.html#servo-motor-code",
    "href": "software.html#servo-motor-code",
    "title": "Software Programs and Design",
    "section": "1. Servo Motor Code",
    "text": "1. Servo Motor Code\nThe Servo Motor was coded mainly through modules angle_decoder and pwm_gen to decide based on the input which angle to open the jaw to. Both modules work in conjunction to open the jaw to the right angle and hold the angle when needed. First, the inputs from the estop and from the MCU, including the capacitive sensor (captouch) and the IR detector (irblock), are sent through the synchronizer to synchronize the inputs. The synchronized inputs are then sent to the angledecoder module which implements an FSM to move from a CLOSED to an OPEN state and then to a SLIGHT state (and back and forth between the three) based on whether the capacitive sensor has been activated or the IR sensor has been activated. servo motor takes in those signals The FSM configuration allowed the angle to be set such that the head would stay fully open until the IR proximity sensor detected a hand and then for the jaw to close just enough to make it feel like the users’ hand is being bitten before returning to the OPEN state. The state only goes back to CLOSED if the estop is triggered for resetting the device for the next user.\nFor output logic, each state was set to different angles. In the CLOSED state the angle is set to 8’d30 for 30 degrees. In the OPENED state it was set to 8’d150 for 150 degrees. In the SLIGHT state the angle is set to 8’d90 for 90 degrees. These weren’t the exact angles we ended up using but were instead used to differentiate between a fully closed, fully open, and slightly open angle when sending this state to the pwmgen module.\nThe angle_decoder then sends 8'd30, 8'd150, or 8d90 to the pwmgen module corresponding to whether the mouth should be closed, open, or slightly open respectively. The servo works interestingly in that instead of a PWM signal at a certain frequency to set the angle, the servo bases the angle on the “on-time pulse width” or how long the PWM is on for. For many hobby servos, the servo motor shaft can be rotated from 0° to 180° by varying the pulse width from 1ms to 2 ms. We used a Wokwi blog to help understand how to control the servo motor. Using this information, in the pwmgen module the output pwm signal is set to toggle on for a period of time based on a counter, toggling LOW once a certain counter value is hit such that the pulse width is only on for that specified amount of clock cycles. The counter value that the pwm output toggles on depends on the angle output from the angledecoder module. In order to have the change between opening, chomping, and closing to be visible, the angledecoder module used the clk_enable signal from the clk_div module to slow down the speed from state to state.\nTo test what the counter values needed to be to reach our desired angles on the mechanical body, we used a seperate test file that sent a hard-coded pwm value to the servo and manually found which counter value matched our desired angles on Toothless’ head."
  },
  {
    "objectID": "software.html#led-array-code",
    "href": "software.html#led-array-code",
    "title": "Software Programs and Design",
    "section": "2. LED Array Code",
    "text": "2. LED Array Code\nThe LED Array used SRAM (Static Rnadom-Access Memory) loaded on the FPGA’s bitstream to play various LED shows. Since SRAM is volatile, the memory resets everytime the FPGA is reset which introduced the problem of the FPGA erasing the LED show upon every boot. However, loading the pattern into the bitstream allowed us to reload in the LED show automatically everytime the FPGA resets instead of having to load in the show manually. The led_pattern module also used an FSM with states OFF, PLAYING, ROARING, and ON. The LED pattern was stored as an 11 bit string for the 5 white LEDs, 5 green LEDs, and 1 purple LED strip.\nWhen it receives a signal from captouch it goes to state PLAYING and plays the pattern of the green LEDs, slowly turning on in sequence, followed by the white ones, and then ending by moving to the ON state with all white LEDs and the purple LED strip on. In the ROARING state the LED pattern flashes the green LEDs on and off three times before returning to the ON state. In order to have the change between each step of the LED sequence to be visible, the led_pattern used the clk_enable signal from the clk_div module to slow down the speed from state to state and step to step such that the eye could see every change clearly."
  },
  {
    "objectID": "software.html#synchronizer-code",
    "href": "software.html#synchronizer-code",
    "title": "Software Programs and Design",
    "section": "3. Synchronizer code",
    "text": "3. Synchronizer code\nThe synchronizer module uses two flip flops to synchronize an asynchronous input and output a synchronous signal to the rest of the modules. The module was used to synchronize the captouch and irblock inputs from the MCU and the estop input from the external button."
  },
  {
    "objectID": "software.html#clock-divider-code",
    "href": "software.html#clock-divider-code",
    "title": "Software Programs and Design",
    "section": "4. Clock divider code",
    "text": "4. Clock divider code\nThe clk_div module uses a counter to slow the internal HSOSC clock down such that the changes between states for the jaw and the LEDs were visible. The module does this by sending a high pulse every 2000000 cycles such that with an internal clock of 24MHz, the states of angledecoder and led_pattern change on a 12Hz frequency."
  },
  {
    "objectID": "members.html#caiya-coggshall-hmc-26",
    "href": "members.html#caiya-coggshall-hmc-26",
    "title": "The Team",
    "section": "",
    "text": "Caiya Coggshall is a senior engineering major at Harvey Mudd College with a concentration in Mechanical, Manufacturing, and Computer systems.\n​Some of her past experience involves fabricating and testing fixtures to support the development of a Class III medical device as a manufacturing engineering intern at E2. She’s prototyped a fully mechanical autoinjector for hormonal acne treatment through Indomo. In research, she managed a cell culture facility and contributed to experimental systems for cancer and nanoparticle drug delivery. On campus, she serves as a machine shop proctor, training students in milling, lathe operation, and various other tooling machines. Lastly, she leads as the external operations coordinator of the tours program at Harvey Mudd College. The link to her personal portfolio can be found here\nShe’s drawn to projects that build real, physical systems and approach every problem with curiosity, attention to detail, and a drive to make things that actually work. After college, she hopes to find a job combining her mechanical and hardware interests to create biomedical devices."
  },
  {
    "objectID": "members.html#erin-wang-hmc-26",
    "href": "members.html#erin-wang-hmc-26",
    "title": "The Team",
    "section": "",
    "text": "Erin Wang is a senior engineering major at Harvey Mudd College. Her love for theme parks like Disney and Universal Studios greatly sparked her interest in robotics and mechatronics specifically for building animatronics. One of her personal projects is to build the robot from the REPO game with 3D printed material and off-the-shelf servo motors. She was extremely excited to be able to bring her passion for animatronics alive through this project. The link to her Github can be found here.\nAfter college, she aims to apply for Masters programs robotics, electrical engineering, or mechanical engineering. When she is not working hard in her classes, music and food fill her life. She loves to dance and sing as well as compose music, and she is always willing to try a new food place."
  }
]